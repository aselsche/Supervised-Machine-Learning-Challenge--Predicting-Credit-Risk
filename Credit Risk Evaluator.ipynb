{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised Machine Learning Homework - Predicting Credit Risk**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>...</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26400.0</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>565.22</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>24.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258000.0</td>\n",
       "      <td>38985.0</td>\n",
       "      <td>48100.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>785.61</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>32.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>427746.0</td>\n",
       "      <td>97284.0</td>\n",
       "      <td>51200.0</td>\n",
       "      <td>116246.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10200.0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>350.10</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28204.0</td>\n",
       "      <td>9242.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>24204.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.2305</td>\n",
       "      <td>423.29</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>58500.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>18.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>30868.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  installment home_ownership  annual_inc  \\\n",
       "0    26400.0    0.1033       565.22       MORTGAGE     70000.0   \n",
       "1    25000.0    0.0819       785.61       MORTGAGE    100000.0   \n",
       "2    10200.0    0.1430       350.10       MORTGAGE     40000.0   \n",
       "3    15000.0    0.2305       423.29       MORTGAGE     58500.0   \n",
       "\n",
       "  verification_status pymnt_plan    dti  delinq_2yrs  inq_last_6mths  ...  \\\n",
       "0        Not Verified          n  24.48          0.0             0.0  ...   \n",
       "1            Verified          n  32.76          0.0             2.0  ...   \n",
       "2        Not Verified          n  20.67          0.0             0.0  ...   \n",
       "3        Not Verified          n  18.99          0.0             2.0  ...   \n",
       "\n",
       "   percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  \\\n",
       "0               0.0                   0.0        0.0         258000.0   \n",
       "1               0.0                   0.0        0.0         427746.0   \n",
       "2             100.0                   0.0        0.0          28204.0   \n",
       "3              25.0                   0.0        0.0          44700.0   \n",
       "\n",
       "  total_bal_ex_mort  total_bc_limit  total_il_high_credit_limit  \\\n",
       "0           38985.0         48100.0                     30000.0   \n",
       "1           97284.0         51200.0                    116246.0   \n",
       "2            9242.0          2500.0                     24204.0   \n",
       "3           30868.0         20000.0                     23000.0   \n",
       "\n",
       "   hardship_flag  debt_settlement_flag    target  \n",
       "0              N                     N  low_risk  \n",
       "1              N                     N  low_risk  \n",
       "2              N                     N  low_risk  \n",
       "3              N                     N  low_risk  \n",
       "\n",
       "[4 rows x 84 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the files\n",
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))\n",
    "# train_df.head()\n",
    "test_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing the Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target column (y) from the predictive features (X) in both our train and test dfs & make a copy of its data\n",
    "X_train = train_df.drop(\"target\", axis=1).copy()\n",
    "X_test = test_df.drop(\"target\", axis=1).copy()\n",
    "y_train = train_df[\"target\"].copy()\n",
    "y_test = test_df[\"target\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>...</th>\n",
       "      <th>verification_status_Source Verified</th>\n",
       "      <th>verification_status_Verified</th>\n",
       "      <th>pymnt_plan_n</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>application_type_Individual</th>\n",
       "      <th>application_type_Joint App</th>\n",
       "      <th>hardship_flag_N</th>\n",
       "      <th>hardship_flag_Y</th>\n",
       "      <th>debt_settlement_flag_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26400.0</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>565.22</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>24.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20070.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>785.61</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>32.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8168.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10200.0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>350.10</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3306.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.2305</td>\n",
       "      <td>423.29</td>\n",
       "      <td>58500.0</td>\n",
       "      <td>18.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12477.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.1102</td>\n",
       "      <td>870.10</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>38.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  installment  annual_inc    dti  delinq_2yrs  \\\n",
       "0    26400.0    0.1033       565.22     70000.0  24.48          0.0   \n",
       "1    25000.0    0.0819       785.61    100000.0  32.76          0.0   \n",
       "2    10200.0    0.1430       350.10     40000.0  20.67          0.0   \n",
       "3    15000.0    0.2305       423.29     58500.0  18.99          0.0   \n",
       "4    40000.0    0.1102       870.10     90000.0  38.87          0.0   \n",
       "\n",
       "   inq_last_6mths  open_acc  pub_rec  revol_bal  ...  \\\n",
       "0             0.0      10.0      0.0    20070.0  ...   \n",
       "1             2.0      13.0      0.0     8168.0  ...   \n",
       "2             0.0       8.0      0.0     3306.0  ...   \n",
       "3             2.0       9.0      0.0    12477.0  ...   \n",
       "4             2.0      15.0      0.0    24111.0  ...   \n",
       "\n",
       "   verification_status_Source Verified  verification_status_Verified  \\\n",
       "0                                    0                             0   \n",
       "1                                    0                             1   \n",
       "2                                    0                             0   \n",
       "3                                    0                             0   \n",
       "4                                    0                             0   \n",
       "\n",
       "   pymnt_plan_n  initial_list_status_f  initial_list_status_w  \\\n",
       "0             1                      0                      1   \n",
       "1             1                      0                      1   \n",
       "2             1                      0                      1   \n",
       "3             1                      0                      1   \n",
       "4             1                      0                      1   \n",
       "\n",
       "   application_type_Individual  application_type_Joint App  hardship_flag_N  \\\n",
       "0                            1                           0                1   \n",
       "1                            0                           1                1   \n",
       "2                            1                           0                1   \n",
       "3                            1                           0                1   \n",
       "4                            1                           0                1   \n",
       "\n",
       "   hardship_flag_Y  debt_settlement_flag_N  \n",
       "0                0                       1  \n",
       "1                0                       1  \n",
       "2                0                       1  \n",
       "3                0                       1  \n",
       "4                0                       1  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "X_train = pd.get_dummies(train_df.drop(columns = ['target']))\n",
    "X_train.head()\n",
    "X_test = pd.get_dummies(test_df.drop(columns = ['target']))\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, add dummy variables that are missing in the testing set\n",
    "cols_to_add = set(X_train.columns) ^ set(X_test.columns)\n",
    "# Loop through each missing column and add it to X_test with all 0s\n",
    "for col in cols_to_add:\n",
    "        X_test[col] = 0\n",
    "        \n",
    "# Set the order of the columns in X_test to match the order of columns in X_train\n",
    "X_test = X_test[X_train.columns]\n",
    "# Encode the target column with 1s and 0s (both train and test)\n",
    "X_test = X_test[X_train.columns]\n",
    "target_encoder = LabelEncoder().fit(y_train)\n",
    "y_train = target_encoder.transform(y_train)\n",
    "y_test=target_encoder.transform(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12180, 92)\n",
      "(8146, 92)\n",
      "(12180,)\n",
      "(8146,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes to make sure X_train and X_test have the same number of columns (same with y_train/y_test)\n",
    "# Check that X_train and y_train have the same number of rows (same with X_test/y_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Predictions***\n",
    "\n",
    "Using an entire year's worth of data (2019), my task is to predict the credit risk of loans from the first quarter of the next year (2020). The data is undersampled to give an even number of high risk and low risk loans. In the original dataset, only 2.2% of loans are categorized as high risk. This analysis is trying to find the best model that can detect if a loan is high risk or not. To come up with a solutiom, I will be using the following models: a LogisticRegression and RandomForestClassifier. The logistic regression will be a better suited model for this credit risk case, which has relatively direct data. The Logistic regression does well on highly correlated data which is true in this case. The random forest fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. But in this case, using the random forest will be overfitting and logistic will be more fitted since the credit risk data that I was provided with is strongly linked together/highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5040510680088387\n",
      "0.6535303776683087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aconnolly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='lbfgs', random_state=24)\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.score(X_test, y_test))\n",
    "print(lr.score(X_train, y_train))\n",
    "# # Logistic regression is coming out with 50% which is bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6977657746133071\n",
      "0.722167487684729\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model train and test score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=35, max_depth=3)\n",
    "rf.fit(X_train, y_train)\n",
    "print(rf.score(X_test, y_test))\n",
    "print(rf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data: we need to scale only the X_train data only that one time\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Use the scaler on X_train and X_test\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# We need to fit preprocessors to training data only! If we fit preprocessors before splitting the data, we're biasing the model with information\n",
    "# from the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8062852933955316\n",
      "0.710919540229885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aconnolly\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "print(lr.score(X_test_scaled, y_test))\n",
    "print(lr.score(X_train_scaled, y_train))\n",
    "\n",
    "#this way we prevented overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6919960716916278\n",
      "0.7269293924466338\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'rf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-dbdaba6e0edd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'rf'"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model train/test score\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "print(rf.score(X_test_scaled, y_test))\n",
    "print(rf.score(X_train_scaled, y_train))\n",
    "\n",
    "rf.rf.feature_importances_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "First, I built a logistic regression as a baseline. Logistic Regresion is good about taking all columns and finding the equation.  Before scaling the data, the score was:\n",
    "0.50 (Test), 0.65 (Train)\n",
    "\n",
    "Then, I scaled the data because it allows the data to be normalized to train the model, which I did by calling the transform() function. After training the Logistic Regression model on the scaled data, it is no longer over-fitting and we went from 50%  to 81%. \n",
    "0.81 (Test), 0.71(Train)\n",
    "\n",
    "Then, RandomForestCLassifier was used. Random forest is really good about finding odd but strong predicitive patterns. I did the same steps here:\n",
    "0.70 (Test), 0.72 (Train)\n",
    "\n",
    "After training the RandomForestCLassifier on the scaled data, the model score was:\n",
    "0.69 (Test), 0.73 (Train)\n",
    "\n",
    "Logistic regression is more fitted for this specific Credit Risk Case because the credit risk data is strongly linked together/highly correlated data and logistic regression is great in identifying direct data connection. RandomForest will be overfitting. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
